speech_to_text {
  alphabet: " abcdefghijklmnopqrstuvwxyz'_";

  pre_process_step {
    stage: TRAIN_AND_EVAL;
    lmfb {
      n_mels: 80;
      win_length: 400;
      hop_length: 160;
    }
  }

  pre_process_step {
    stage: TRAIN_AND_EVAL;
    standardize {
    }
  }
  pre_process_step {
    stage: TRAIN_AND_EVAL;
    context_frames {
      n_context: 2;
    }
  }


  rnn_t {
    rnn_t_encoder {
      fc1 {
      num_hidden_layers: 1;
      hidden_size: 1152;
      dropout: 0.25;
      activation {
        hardtanh {
          min_val: 0.0;
          max_val: 20.0;
          }
        }
      }
      rnn1 {
        rnn_type: LSTM;
        hidden_size: 1152;
        num_layers: 2;
        bias: true;
        bidirectional: false;
            }
      time_reduction_factor: 2;

      rnn2 {
        rnn_type: LSTM;
        hidden_size: 128;
        num_layers: 1;
        bias: true;
        bidirectional: false;
      }

      fc2 {
      num_hidden_layers: 1;
      hidden_size: 800;
      dropout: 0.25;
      activation {
        hardtanh {
          min_val: 0.0;
          max_val: 20.0;
          }
        }
      }
    }
    dec_rnn {
      rnn_type: LSTM;
      hidden_size: 256;
      num_layers: 2;
      bias: true;
      bidirectional: false;
      batch_first: true;
    }

    fully_connected {
      num_hidden_layers: 1;
      hidden_size: 512;
      dropout: 0.25;
      activation {
        hardtanh {
          min_val: 0.0;
          max_val: 20.0;
        }
      }
    }

  }
  rnn_t_loss {
    blank_index: 28;
    reduction: SUM;
  }

  rnn_t_greedy_decoder {
    blank_index: 28;
    max_symbols_per_step: 100;
  }
}

  train_config {
    batch_size: 2;
    epochs: 40;
    adam {
      learning_rate: 0.0003;
    }
    dataset {
      librispeech {
        root: "/data/";
        subset: TRAIN_CLEAN_100;
        subset: TRAIN_CLEAN_360;
        subset: TRAIN_OTHER_500;
        max_secs {
          value: 16.7;
        }
      }
    }
    shuffle_batches_before_every_epoch: true;
  }

  eval_config {
    batch_size: 2;
    dataset {
      librispeech {
        root: "~/Data/LibriSpeech/";
        subset: DEV_CLEAN;
      }
    }
  }
