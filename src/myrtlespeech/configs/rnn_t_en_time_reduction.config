speech_to_text {
  alphabet: " abcdefghijklmnopqrstuvwxyz'_";

  pre_process_step {
    stage: TRAIN_AND_EVAL;
    mfcc {
      n_mfcc: 80;
      win_length: 400;
      hop_length: 160;
    }
  }

  pre_process_step {
    stage: TRAIN_AND_EVAL;
    standardize {
    }
  }


  rnn_t {
    rnn_t_encoder {
      rnn1 {
        rnn_type: LSTM;
        hidden_size: 128;
        num_layers: 1;
        bias: true;
        bidirectional: false;
            }
      time_reduction_factor: 2;
      rnn2 {
        rnn_type: LSTM;
        hidden_size: 128;
        num_layers: 1;
        bias: true;
        bidirectional: false;
            }
    }

    dec_rnn {
      rnn_type: LSTM;
      hidden_size: 128;
      num_layers: 2;
      bias: true;
      bidirectional: false;
      batch_first: true;
    }

    fully_connected {
      num_hidden_layers: 2;
      hidden_size: 128;
      activation {
        hardtanh {
          min_val: 0.0;
          max_val: 20.0;
        }
      }
    }

  }
  rnn_t_loss {
    blank_index: 28;
    reduction: SUM;
  }

  rnn_t_beam_decoder {
    blank_index: 28;
    max_symbols_per_step: 4;
    beam_width: 8;
  }
}

  train_config {
    batch_size: 8;
    epochs: 1;
    adam {
      learning_rate: 0.01;
    }
    dataset {
      librispeech {
        root: "~/Data/LibriSpeech/";
        subset: TRAIN_CLEAN_100;
        max_secs {
          value: 16.7;
        }
      }
    }
    shuffle_batches_before_every_epoch: true;
  }

  eval_config {
    batch_size: 8;
    dataset {
      librispeech {
        root: "~/Data/LibriSpeech/";
        subset: DEV_CLEAN;
      }
    }
  }
