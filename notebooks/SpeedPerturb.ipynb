{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Speed Pertubation\n",
    "Speed pertubation acts on the audio signal itself so it cannot (? should not) be applied once the audio signal is in torch.tensor form. Currently we load audio with:  \n",
    "\n",
    "``\n",
    "audio, rate = torchaudio.load(path)\n",
    "``\n",
    "This uses the loading capabilities in the selected backend. In all practical cases (i.e. except on windows) the backend used will be sox. \n",
    "\n",
    "Note that in the mlperf repo we use ``librosa`` to perform speed pertubation but this would involve adding another dependency and massively complicating the dataset transforms control flow which I am not willing to do. \n",
    "\n",
    "NOTE: it will be necessary to create a _Dataset parent class so that CommonVoice and LibriSpeech can share the same ``__get_item__``. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch,torchaudio\n",
    "import librosa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = '/home/julian/Music/BTB2.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, rate = torchaudio.load(fp)\n",
    "\n",
    "assert rate == 16000, f\"{path} sample rate == {rate} != 16000\"\n",
    "audio.shape # channels, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MyDataset(Dataset):\n",
    "#     def __init__(self, audiodir_path):\n",
    "#         self.data = [os.path.join(audiodir_path, fn) for fn in os.listdir(audiodir_path)]\n",
    "#         self.E = torchaudio.sox_effects.SoxEffectsChain()\n",
    "#         self.E.append_effect_to_chain(\"rate\", [16000])  # resample to 16000hz\n",
    "#         self.E.append_effect_to_chain(\"channels\", [\"1\"])  # mono signal\n",
    "#     def __getitem__(self, index):\n",
    "#         fn = self.data[index]\n",
    "#         self.E.set_input_file(fn)\n",
    "#         x, sr = self.E.sox_build_flow_effects()\n",
    "#         return x, sr\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "# torchaudio.initialize_sox()\n",
    "# ds = MyDataset(path_to_audio_files)\n",
    "# for sig, sr in ds:\n",
    "#   [do something here]\n",
    "# torchaudio.shutdown_sox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchaudio.initialize_sox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do this with each speed\n",
    "def speed_perturb(speed, fp):\n",
    "    chain = torchaudio.sox_effects.SoxEffectsChain()\n",
    "    chain.append_effect_to_chain('speed', [speed])\n",
    "    chain.append_effect_to_chain('rate', 16000)\n",
    "    chain.set_input_file(fp)\n",
    "    return chain.sox_build_flow_effects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.set_input_file(fp)\n",
    "x, sr = chain.sox_build_flow_effects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, _ = speed_perturb(0.85, fp)\n",
    "x2, _ = speed_perturb(0.85, fp)\n",
    "x1.shape, x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchaudio.shutdown_sox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn1(path):\n",
    "    return torchaudio.load(path)\n",
    "def fn2(path):\n",
    "    E = torchaudio.sox_effects.SoxEffectsChain()\n",
    "    E.append_effect_to_chain('speed', [1.15])\n",
    "    E.append_effect_to_chain('rate', 16000)\n",
    "    E.set_input_file(path)\n",
    "    return E.sox_build_flow_effects()\n",
    "def fn3(path):\n",
    "    audio, rate = torchaudio.load(path)\n",
    "    audio = librosa.effects.time_stretch(np.asfortranarray(audio.numpy()[0]),1 )\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cProfile.run('fn1(fp)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cProfile.run('fn2(fp)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cProfile.run('fn3(fp)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
