{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing `deepspeech_internal` and `myrtlespeech` rnnt implementations\n",
    "Conclusion - there were differences that made the results not equivalent:\n",
    "1. The packed sequence in the `myrtlespeech` implementation requires the length of the sequence. This was off by one because the SOS token was added. This means the final element in the `myrtlespeech` target sequence was not being considered during training. When this is fixed, the WER = 24.6058% on dev-clean. \n",
    "2. There is no subsampling in the preprocessing of `myrtlespeech` so the network recieves audio inputs at twice the resolution that the weights were trained at in `deepspeech_internal`.\n",
    "3. Different preprocessing `python_speech_features` vs `torchaudio` this may be simply because the values are not exactly the same OR it may suggest the `myrtlespeech` pp is not good at extracting features.\n",
    "4. Activations - x2 extra hardtanhs in encoder. \n",
    "3. Left context vs symmetric context - this may be relevant at the start of the sequence - i.e. the network learns it is at the SOS when there are zeros in the leftmost frames??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsi.rnnt_dsi import Network as RNNT_DSI\n",
    "from myrtlespeech.builders.rnn_t import build as build_rnn_t\n",
    "from myrtlespeech.protos import task_config_pb2\n",
    "\n",
    "\n",
    "import torch\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = 80\n",
    "ncontext = 4\n",
    "vocab_size=28\n",
    "rnnt_dsi = RNNT_DSI(input_features * ncontext, vocab_size)\n",
    "rnnt_dsi.is_half = False\n",
    "rnnt_dsi.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build rnnt_ms\n",
    "with open(\"src/myrtlespeech/configs/rnn_t_en_ds_int.config\") as f:\n",
    "    task_config = text_format.Merge(f.read(), task_config_pb2.TaskConfig())\n",
    "\n",
    "rnnt_ms = build_rnn_t(task_config.speech_to_text.rnn_t, \n",
    "                      input_features=input_features,\n",
    "                      input_channels=ncontext + 1,\n",
    "                      vocab_size = vocab_size)\n",
    "rnnt_ms.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_params = sum([p.numel() for _, p in rnnt_ms.named_parameters()])\n",
    "print(ms_params)\n",
    "dsi_params = sum([p.numel() for _, p in rnnt_dsi.named_parameters()])\n",
    "print(dsi_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make weights the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                   #ds_int: ms\n",
    "dict_map_partial = {\"encoder.0\": \"encode.fc1.fully_connected.0\",\n",
    "               \"encoder.3\": \"encode.fc1.fully_connected.3\",\n",
    "               \"encoder.6.layers.0\": \"encode.rnn1\",\n",
    "               \"encoder.6.layers.2.rnn.weight_ih_l0\": \"encode.rnn1.rnn.weight_ih_l1\",\n",
    "               \"encoder.6.layers.2.rnn.weight_hh_l0\": \"encode.rnn1.rnn.weight_hh_l1\",\n",
    "               \"encoder.6.layers.2.rnn.bias_ih_l0\": \"encode.rnn1.rnn.bias_ih_l1\",\n",
    "               \"encoder.6.layers.2.rnn.bias_hh_l0\": \"encode.rnn1.rnn.bias_hh_l1\",\n",
    "                \"encoder.8\": \"encode.fc2.fully_connected.0\",\n",
    "                \"encoder.11\": \"encode.fc2.fully_connected.3\",\n",
    "                \"prediction.dec_rnn.layers.0\": \"predict_net.dec_rnn\",\n",
    "                \"prediction.dec_rnn.layers.2.rnn.weight_ih_l0\": \"predict_net.dec_rnn.rnn.weight_ih_l1\",\n",
    "                \"prediction.dec_rnn.layers.2.rnn.weight_hh_l0\": \"predict_net.dec_rnn.rnn.weight_hh_l1\",\n",
    "                \"prediction.dec_rnn.layers.2.rnn.bias_ih_l0\": \"predict_net.dec_rnn.rnn.bias_ih_l1\",\n",
    "                \"prediction.dec_rnn.layers.2.rnn.bias_hh_l0\": \"predict_net.dec_rnn.rnn.bias_hh_l1\",\n",
    "                \"prediction.embed\": \"predict_net.embed\",\n",
    "            \"joint_net.0\": \"joint_net.fully_connected.fully_connected.0\",\n",
    "            \"joint_net.3\": \"joint_net.fully_connected.fully_connected.3\"}\n",
    "\n",
    "def get_keys(model_):\n",
    "    keys = []\n",
    "    for k, _ in model_.named_parameters():\n",
    "        keys.append(k)\n",
    "    return keys\n",
    "\n",
    "dict_map = {}\n",
    "ms_keys = get_keys(rnnt_ms) \n",
    "dsi_keys = get_keys(rnnt_dsi)\n",
    "for mskey in ms_keys:\n",
    "    found_key = False\n",
    "    for p_dsikey, p_mskey in dict_map_partial.items():\n",
    "        \n",
    "        if p_mskey in mskey:\n",
    "            dsikey = mskey.replace(p_mskey, p_dsikey)\n",
    "            dict_map[dsikey] = mskey\n",
    "            found_key = True\n",
    "    assert found_key == True, f\"Did not find key={mskey}\"\n",
    "dict_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## update to same params (put dsi weights into ms network)\n",
    "state_dict_ms = rnnt_ms.state_dict()\n",
    "\n",
    "for dsikey, param in rnnt_dsi.named_parameters():\n",
    "    mskey = dict_map[dsikey]\n",
    "    state_dict_ms[mskey] = param\n",
    "\n",
    "\n",
    "rnnt_ms.load_state_dict(state_dict_ms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnnt_dsi.cpu()\n",
    "rnnt_ms.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 2\n",
    "input_channels = ncontext + 1\n",
    "label_seq_len = 3\n",
    "seq_len = 4\n",
    "\n",
    "\n",
    "x = torch.empty((batch, input_channels, input_features, seq_len)).normal_()\n",
    "seq_lens = torch.randint(\n",
    "    low=1, high=seq_len, size=(batch,), dtype=torch.long\n",
    ")\n",
    "y = torch.randint(\n",
    "    low=0,\n",
    "    high=vocab_size - 1,\n",
    "    size=(batch, label_seq_len),\n",
    "    dtype=torch.long,\n",
    ")\n",
    "label_seq_lens = torch.randint(\n",
    "    low=1, high=label_seq_len, size=(batch,), dtype=torch.long\n",
    ")\n",
    "input_ms = ((x, y), (seq_lens, label_seq_lens))\n",
    "\n",
    "\n",
    "## now create for dsi\n",
    "x_dsi = x[:,1:] #\n",
    "\n",
    "_, C, _, _ = x_dsi.shape # get new channel size\n",
    "\n",
    "assert C == ncontext\n",
    "x_dsi = x_dsi.view(batch, C * input_features, seq_len) #B, F, T\n",
    "x_dsi = x_dsi.permute(2, 0, 1).contiguous()\n",
    "\n",
    "input_dsi = (x_dsi, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_len = True\n",
    "if fixed_len:\n",
    "    x = torch.empty((batch, input_channels, input_features, seq_len)).normal_()\n",
    "\n",
    "    seq_lens = torch.randint(\n",
    "        low=1, high=seq_len, size=(batch,), dtype=torch.long\n",
    "    )\n",
    "    seq_lens = torch.IntTensor([seq_len] * batch)\n",
    "    y = torch.randint(\n",
    "        low=0,\n",
    "        high=vocab_size - 1,\n",
    "        size=(batch, label_seq_len),\n",
    "        dtype=torch.long,\n",
    "    )\n",
    "\n",
    "    label_seq_lens = torch.randint(\n",
    "        low=1, high=label_seq_len, size=(batch,), dtype=torch.long\n",
    "    )\n",
    "    label_seq_lens = torch.IntTensor([label_seq_len] * batch)\n",
    "\n",
    "    input_ms = ((x, y), (seq_lens, label_seq_lens))\n",
    "\n",
    "\n",
    "    ## now create for dsi\n",
    "    x_dsi = x[:,1:] #\n",
    "\n",
    "    _, C, _, _ = x_dsi.shape # get new channel size\n",
    "\n",
    "    assert C == ncontext, f\"{C} != {ncontext}\"\n",
    "    x_dsi = x_dsi.view(batch, C * input_features, seq_len) #B, F, T\n",
    "    x_dsi = x_dsi.permute(2, 0, 1).contiguous()\n",
    "\n",
    "    input_dsi = (x_dsi, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_out, _ = rnnt_ms(input_ms)\n",
    "ms_out = ms_out.cpu()\n",
    "ms_out.shape\n",
    "\n",
    "dsi_out = rnnt_dsi(input_dsi)\n",
    "dsi_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(dsi_out, ms_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check individual elements of network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder \n",
    "\n",
    "enc_dsi_out = rnnt_dsi.encode(input_dsi[0])\n",
    "enc_ms_out = rnnt_ms.encode((input_ms[0][0], input_ms[1][0]))\n",
    "enc_dsi_out = enc_dsi_out.cpu()\n",
    "enc_ms_out = enc_ms_out[0].cpu(), enc_ms_out[1]\n",
    "\n",
    "assert torch.allclose(enc_dsi_out, enc_ms_out[0].transpose(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "pred_dsi_out, _ = rnnt_dsi.predict(input_dsi[1])\n",
    "pred_ms_out = rnnt_ms.prediction((input_ms[0][1], input_ms[1][1]))\n",
    "\n",
    "print(pred_dsi_out.shape)\n",
    "print(pred_ms_out[0].shape)\n",
    "assert torch.allclose(pred_dsi_out, pred_ms_out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dec_rnn\n",
    "y = torch.empty((batch, label_seq_len, 256)).normal_()\n",
    "y_dsi = y.transpose(1, 0)\n",
    "y_lens = input_ms[1][1]\n",
    "y_lens = torch.IntTensor([label_seq_len, label_seq_len])\n",
    "state = None\n",
    "\n",
    "dec_rnn_dsi_out, dec_rnn_dsi_hid = rnnt_dsi.prediction[\"dec_rnn\"](y_dsi, state)\n",
    "(dec_rnn_ms_out, dec_rnn_ms_hid), lengths = rnnt_ms.dec_rnn(((y, state), y_lens))\n",
    "lengths, label_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dec_rnn_dsi_hid = dec_rnn_dsi_hid[0].squeeze(1), dec_rnn_dsi_hid[1].squeeze(1)\n",
    "assert torch.allclose(dec_rnn_dsi_out, dec_rnn_ms_out.transpose(1, 0))\n",
    "assert torch.allclose(dec_rnn_ms_hid[0], dec_rnn_dsi_hid[0])\n",
    "assert torch.allclose(dec_rnn_ms_hid[1], dec_rnn_dsi_hid[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for idx, (dsi_name, dsi_param) in enumerate(rnnt_dsi.prediction[\"dec_rnn\"].named_parameters()):\n",
    "    for idx_2, (rnnt_name, rnnt_param) in enumerate(rnnt_ms.dec_rnn.named_parameters()):\n",
    "        if idx == idx_2:\n",
    "            print(dsi_name, rnnt_param.type(), dsi_param.type())\n",
    "            assert torch.allclose(rnnt_param, dsi_param)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(dec_rnn_dsi_hid[0], dec_rnn_ms_hid[0])\n",
    "assert torch.allclose(dec_rnn_ms_out[0], dec_rnn_dsi_out.transpose(1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in rnnt_ms.named_parameters():\n",
    "    print(param.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
