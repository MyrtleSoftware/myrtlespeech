{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling\n",
    "### Key results\n",
    "* v2 slower than v1 due to `torch.cat` operation. \n",
    "* Locally CPU vs brahe CPU: local CPU v2_script version is slower than v2. This difference dissapears on brahe (although brahe max memory usage is lower)\n",
    "* GPU: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" # set this before importing torchimport torch \n",
    "import torch \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myrtlespeech.model.hard_lstm import HardLSTM as HardLSTM_ver2\n",
    "from myrtlespeech.model.hard_lstm2 import HardLSTM as HardLSTM_ver3\n",
    "\n",
    "from hard import HardLSTM as HardLSTM_ver1\n",
    "\n",
    "from deepspeech_int import HardLSTM as HardLSTM_dsi\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import List\n",
    "from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_args(in_size, hidden, seq_len, num_layers, bidirectional, batch, gpu=False):\n",
    "    x = torch.randn(seq_len, batch, in_size)\n",
    "    num_directions = 2 if bidirectional else 1\n",
    "    zeros = torch.zeros(\n",
    "        num_layers * num_directions,\n",
    "        batch,\n",
    "        hidden,\n",
    "        dtype=x.dtype,\n",
    "    )\n",
    "    if gpu:\n",
    "        x = x.cuda()\n",
    "        zeros = zeros.cuda()\n",
    "    return (x, (zeros, zeros))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check everything runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 100\n",
    "hidden = 128\n",
    "seq_len = 35\n",
    "num_layers = 1\n",
    "bidirectional = True\n",
    "batch = 3\n",
    "\n",
    "args = gen_args(input_size, hidden, seq_len, num_layers, bidirectional, batch)\n",
    "\n",
    "lstm_v1 = HardLSTM_ver1(input_size=input_size, hidden_size=hidden, batch_first=False, bidirectional=bidirectional)\n",
    "lstm_v2 = HardLSTM_ver2(input_size=input_size, hidden_size=hidden, batch_first=False, bidirectional=bidirectional)\n",
    "lstm_v2_script = torch.jit.script(HardLSTM_ver2(input_size=input_size, hidden_size=hidden, batch_first=False, bidirectional=bidirectional))\n",
    "lstm_v3 = HardLSTM_ver3(input_size=input_size, hidden_size=hidden, batch_first=False, bidirectional=bidirectional)\n",
    "lstm_v3_script = torch.jit.script(HardLSTM_ver3(input_size=input_size, hidden_size=hidden, batch_first=False, bidirectional=bidirectional))\n",
    "\n",
    "lstm = torch.nn.LSTM(input_size=input_size, hidden_size=hidden, batch_first=False, bidirectional=bidirectional)\n",
    "\n",
    "outputs_v1 = lstm_v1(*args)\n",
    "outputs_v2 = lstm_v2(*args)\n",
    "outputs_v2_script = lstm_v2_script(*args)\n",
    "outputs_v3 = lstm_v3(*args)\n",
    "outputs_v3_script = lstm_v3_script(*args)\n",
    "outputs_n = lstm(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, (h, c) = outputs_n\n",
    "print(y.shape, h.shape, c.shape)\n",
    "y, (h, c) = outputs_v3_script\n",
    "print(y.shape, h.shape, c.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_name = {\n",
    "    0: \"Input Size\",\n",
    "    1: \"Hidden Size\",\n",
    "    2: \"Sequence Length\",\n",
    "    3: \"Number Layers\",\n",
    "    4: \"bidirectional\",\n",
    "    5: \"Batch Size\",\n",
    "}\n",
    "def profile_and_plot(models, dims, construct_each_time = False, batch_first=False, gpu=False):\n",
    "    \"\"\"One and only one of dims is a List. All others are constants.\n",
    "    \n",
    "    dims = (in_size, hidden, seq_len, num_layers, bidirectional, batch)\n",
    "    \n",
    "    \"\"\"\n",
    "    list_seen = False\n",
    "    for idx, dim in enumerate(dims):\n",
    "        if isinstance(dim, List):\n",
    "            assert list_seen == False, \"Only one List can be present\"\n",
    "            list_seen = True\n",
    "            list_idx = idx\n",
    "    assert list_seen == True, \"There must be a List present\"\n",
    "    \n",
    "    values = dims[list_idx]\n",
    "    results = {k : [] for k in models.keys()}\n",
    "    \n",
    "    if not construct_each_time:\n",
    "        lstms = {}\n",
    "        for name, lstm_constr in models.items():\n",
    "            dims_in = copy(dims)\n",
    "            dims_in[list_idx] = values[0]\n",
    "            lstm = lstm_constr(dims_in[0], dims_in[1], batch_first=batch_first, bidirectional=dims_in[4])\n",
    "            if gpu:\n",
    "                lstm.cuda()\n",
    "            # warmup\n",
    "            args = gen_args(*dims_in, gpu=gpu)\n",
    "            lstm(*args)\n",
    "            # add to dict\n",
    "            lstms[name] = lstm \n",
    "    \n",
    "    for value in values:\n",
    "        dims_in = copy(dims)\n",
    "        dims_in[list_idx] = value\n",
    "        args = gen_args(*dims_in, gpu=gpu)\n",
    "\n",
    "        for name, lstm_constr in models.items():\n",
    "            if construct_each_time:\n",
    "                lstm = lstm_constr(dims_in[0], dims_in[1], batch_first=batch_first, bidirectional=dims_in[4])\n",
    "                if gpu:\n",
    "                    lstm.cuda()\n",
    "                # warmup\n",
    "                outputs = lstm(*args)\n",
    "            else:\n",
    "                lstm = lstms[name]\n",
    "\n",
    "            # time\n",
    "            t0 = time.perf_counter() \n",
    "            lstm(*args)\n",
    "            tend = time.perf_counter() \n",
    "            results[name].append((value, tend-t0))\n",
    "            if construct_each_time:\n",
    "                del lstm \n",
    "            \n",
    "    \n",
    "    # plot\n",
    "    for k, res in results.items():\n",
    "        res_ = list(zip(*res))\n",
    "        plt.plot(res_[0], res_[1], label=k)\n",
    "        plt.xlabel(f\"{idx_to_name[list_idx]}\")\n",
    "        plt.ylabel(\"Time /s\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_script_constructor(constructor):\n",
    "    \n",
    "    def cstor(*args, **kwargs):\n",
    "        model = constructor(*args, **kwargs).cuda()\n",
    "        return torch.jit.script(model)\n",
    "    return cstor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models =  {#\"Version1\": HardLSTM_ver1, \n",
    "           #\"Version2\": HardLSTM_ver2, \n",
    "           #\"Version2_scripted\": get_script_constructor(HardLSTM_ver2),\n",
    "           #\"Version3\": HardLSTM_ver3, \n",
    "           \"Version3_scripted\": get_script_constructor(HardLSTM_ver3),\n",
    "           \"PyTorch\": torch.nn.LSTM}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_size = 1024\n",
    "hidden = 1024\n",
    "seq_len = [1] + list(range(32, 1024, 32))\n",
    "num_layers = 1\n",
    "bidirectional = True\n",
    "batch = 256\n",
    "\n",
    "dims = [in_size, hidden, seq_len, num_layers, bidirectional, batch]\n",
    "\n",
    "\n",
    "#results = profile_and_plot(models, dims, construct_each_time=False)\n",
    "results = profile_and_plot(models, dims, construct_each_time=False, gpu=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# much smaller\n",
    "in_size = 128\n",
    "hidden = 128\n",
    "seq_len = [1] + list(range(32, 1024, 32))\n",
    "num_layers = 1\n",
    "bidirectional = False\n",
    "batch = 32\n",
    "\n",
    "dims = [in_size, hidden, seq_len, num_layers, bidirectional, batch]\n",
    "\n",
    "\n",
    "#results = profile_and_plot(models, dims, construct_each_time=False)\n",
    "results = profile_and_plot(models, dims, construct_each_time=False, gpu=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = list(range(2, 750, 30))\n",
    "bidirectional = True\n",
    "\n",
    "dims = [in_size, hidden, seq_len, num_layers, bidirectional, batch]\n",
    "\n",
    "results = profile_and_plot(models, dims, construct_each_time=False, gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variation with batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_size = 100\n",
    "hidden = 256\n",
    "seq_len = 100\n",
    "num_layers = 1\n",
    "bidirectional = False\n",
    "batch = list(range(2, 512, 8))\n",
    "\n",
    "\n",
    "dims = [in_size, hidden, seq_len, num_layers, bidirectional, batch]\n",
    "\n",
    "results = profile_and_plot(models, dims, construct_each_time=False)\n",
    "results = profile_and_plot(models, dims, construct_each_time=False, gpu=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidirectional = True\n",
    "batch = list(range(2, 252, 8))\n",
    "\n",
    "dims = [in_size, hidden, seq_len, num_layers, bidirectional, batch]\n",
    "\n",
    "results = profile_and_plot(models, dims, construct_each_time=False)\n",
    "results = profile_and_plot(models, dims, construct_each_time=False, gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_size = list(range(1, 2048, 32))\n",
    "hidden = 1024\n",
    "seq_len = 256\n",
    "num_layers = 1\n",
    "bidirectional = False\n",
    "batch = 128\n",
    "\n",
    "dims = [in_size, hidden, seq_len, num_layers, bidirectional, batch]\n",
    "\n",
    "results = profile_and_plot(models, dims, construct_each_time=True, gpu=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidirectional = True\n",
    "in_size = list(range(1, 1024, 32))\n",
    "\n",
    "\n",
    "dims = [in_size, hidden, seq_len, num_layers, bidirectional, batch]\n",
    "\n",
    "results = profile_and_plot(models, dims, construct_each_time=True, gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_size = 1024\n",
    "hidden = list(range(2, 2048, 32))\n",
    "num_layers = 1\n",
    "bidirectional = False\n",
    "batch = 128\n",
    "seq_len = 256\n",
    "\n",
    "dims = [in_size, hidden, seq_len, num_layers, bidirectional, batch]\n",
    "\n",
    "results = profile_and_plot(models, dims, construct_each_time=True, gpu=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidirectional = True\n",
    "hidden = list(range(2, 1024, 32))\n",
    "\n",
    "dims = [in_size, hidden, seq_len, num_layers, bidirectional, batch]\n",
    "\n",
    "\n",
    "results = profile_and_plot(models, dims, construct_each_time=True)\n",
    "results = profile_and_plot(models, dims, construct_each_time=True, gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### timit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "hidden_size = 1024\n",
    "batch = 128\n",
    "seq_len = 256\n",
    "x = torch.empty((seq_len, batch, hidden_size)).normal_().to(device)\n",
    "state = (torch.empty((1, batch, hidden_size)).normal_().to(device), torch.empty((1, batch, hidden_size)).normal_().to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_v3 = models['Version3_scripted'](1024, 1024, bidirectional=False).to(device)\n",
    "x = torch.empty((seq_len, batch, hidden_size)).normal_().to(device)\n",
    "state = (torch.empty((1, batch, hidden_size)).normal_().to(device), torch.empty((1, batch, hidden_size)).normal_().to(device))\n",
    "lstm_v3(x, state)\n",
    "%timeit -n 100 lstm_v3(x, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_v2 = models['Version1'](1024, 1024, bidirectional=False).to(device)\n",
    "\n",
    "%timeit -n 100 lstm_v2(x, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = models['PyTorch'](1024, 1024, bidirectional=False).to(device)\n",
    "\n",
    "%timeit -n 100 lstm(x, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_v3 = models['Version3_scripted'](1024, 1024, bidirectional=False).to(device)\n",
    "\n",
    "%timeit -n 2 lstm_v3(x, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = models['PyTorch'](1024, 1024, bidirectional=False).to(device)\n",
    "\n",
    "%timeit -n 5 lstm(x, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = models['PyTorch'](1024, 1024, bidirectional=False).to(device)\n",
    "lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profile version1 and version2 diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "from myrtlespeech.model.hard_lstm import HardLSTM as HardLSTM_ver2\n",
    "from hard import HardLSTM as HardLSTM_ver1\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # set this before importing torchimport torch \n",
    "import torch \n",
    "import time\n",
    "def gen_args(in_size, hidden, seq_len, num_layers, bidirectional, batch, gpu=False):\n",
    "    x = torch.randn(seq_len, batch, in_size)\n",
    "    num_directions = 2 if bidirectional else 1\n",
    "    zeros = torch.zeros(\n",
    "        num_layers * num_directions,\n",
    "        batch,\n",
    "        hidden,\n",
    "        dtype=x.dtype,\n",
    "    )\n",
    "    if gpu:\n",
    "        x = x.cuda()\n",
    "        zeros = zeros.cuda()\n",
    "    return (x, (zeros, zeros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_size = 100\n",
    "hidden = 512\n",
    "seq_len = 100\n",
    "num_layers = 1\n",
    "bidirectional = False\n",
    "batch = 300\n",
    "dims = in_size, hidden, seq_len, num_layers, bidirectional, batch\n",
    "args = gen_args(*dims)\n",
    "\n",
    "lstm_v1 = HardLSTM_ver1(dims[0], dims[1], batch_first=False, bidirectional=dims[4])\n",
    "lstm_v2 = HardLSTM_ver2(dims[0], dims[1], batch_first=False, bidirectional=dims[4])\n",
    "lstm_v2_script = torch.jit.script(HardLSTM_ver2(dims[0], dims[1], batch_first=False, bidirectional=dims[4]))\n",
    "lstm = torch.nn.LSTM(dims[0], dims[1], batch_first=False, bidirectional=dims[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_v1(*args)\n",
    "cProfile.run('lstm_v1(*args)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_v2(*args)\n",
    "cProfile.run('lstm_v2(*args)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_v2_script(*args)\n",
    "cProfile.run('lstm_v2_script(*args)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm(*args)\n",
    "cProfile.run('lstm(*args)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_myrtlespeech)",
   "language": "python",
   "name": "conda_myrtlespeech"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
