{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN-T Overfitting\n",
    "Validate that all elements of the pipeline are working by overfitting to a small number of training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import typing\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from google.protobuf import text_format\n",
    "\n",
    "from myrtlespeech.model.rnn_t import RNNT\n",
    "from myrtlespeech.run.callbacks.csv_logger import CSVLogger\n",
    "from myrtlespeech.run.callbacks.callback import Callback, ModelCallback\n",
    "from myrtlespeech.run.callbacks.clip_grad_norm import ClipGradNorm\n",
    "from myrtlespeech.run.callbacks.report_mean_batch_loss import ReportMeanBatchLoss\n",
    "from myrtlespeech.run.callbacks.stop_epoch_after import StopEpochAfter\n",
    "from myrtlespeech.run.callbacks.mixed_precision import MixedPrecision\n",
    "from myrtlespeech.post_process.utils import levenshtein\n",
    "from myrtlespeech.builders.task_config import build\n",
    "from myrtlespeech.run.train import fit\n",
    "from myrtlespeech.protos import task_config_pb2\n",
    "from myrtlespeech.run.stage import Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the RNNT model defined in the config file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speech_to_text {\n",
       "  alphabet: \" abcdefghijklmnopqrstuvwxyz\\'_\"\n",
       "  pre_process_step {\n",
       "    stage: TRAIN_AND_EVAL\n",
       "    lmfb {\n",
       "      n_mels: 80\n",
       "      win_length: 400\n",
       "      hop_length: 160\n",
       "    }\n",
       "  }\n",
       "  pre_process_step {\n",
       "    stage: TRAIN_AND_EVAL\n",
       "    standardize {\n",
       "    }\n",
       "  }\n",
       "  pre_process_step {\n",
       "    stage: TRAIN_AND_EVAL\n",
       "    left_context_frames {\n",
       "      n_context: 3\n",
       "      subsample: 3\n",
       "    }\n",
       "  }\n",
       "  rnn_t {\n",
       "    transcription {\n",
       "      n_hidden: 1152\n",
       "      rnn_layers: 2\n",
       "    }\n",
       "    prediction {\n",
       "      n_hidden: 256\n",
       "      rnn_layers: 2\n",
       "    }\n",
       "    joint {\n",
       "      n_hidden: 512\n",
       "    }\n",
       "  }\n",
       "  rnn_t_loss {\n",
       "    blank_index: 28\n",
       "    reduction: SUM\n",
       "  }\n",
       "  rnn_t_greedy_decoder {\n",
       "    blank_index: 28\n",
       "    max_symbols_per_step: 30\n",
       "  }\n",
       "}\n",
       "train_config {\n",
       "  batch_size: 8\n",
       "  epochs: 40\n",
       "  adam {\n",
       "    learning_rate: 0.0003000000142492354\n",
       "  }\n",
       "  dataset {\n",
       "    librispeech {\n",
       "      root: \"/data/\"\n",
       "      subset: DEV_CLEAN\n",
       "      max_secs {\n",
       "        value: 16.700000762939453\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  shuffle_batches_before_every_epoch: true\n",
       "}\n",
       "eval_config {\n",
       "  batch_size: 8\n",
       "  dataset {\n",
       "    librispeech {\n",
       "      root: \"/data/\"\n",
       "      subset: DEV_CLEAN\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse example config file\n",
    "with open(\"../src/myrtlespeech/configs/rnn_t_en.config\") as f:\n",
    "    task_config = text_format.Merge(f.read(), task_config_pb2.TaskConfig())\n",
    "\n",
    "task_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpeechToText(\n",
       "  (alphabet): Alphabet(symbols=[' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', \"'\", '_'])\n",
       "  (model): RNNT(\n",
       "    (encoder): Sequential(\n",
       "      (0): Linear(in_features=320, out_features=1152, bias=True)\n",
       "      (1): Hardtanh(min_val=0.0, max_val=20.0)\n",
       "      (2): Dropout(p=0.25, inplace=False)\n",
       "      (3): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "      (4): Hardtanh(min_val=0.0, max_val=20.0)\n",
       "      (5): Dropout(p=0.25, inplace=False)\n",
       "      (6): BNRNNSum(\n",
       "        (layers): ModuleList(\n",
       "          (0): RNNLayer(\n",
       "            (rnn): LSTM(1152, 1152)\n",
       "          )\n",
       "          (1): Dropout(p=0.25, inplace=False)\n",
       "          (2): RNNLayer(\n",
       "            (rnn): LSTM(1152, 1152)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): Lambda(lambda_fn=Access RNN output)\n",
       "      (8): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "      (9): Hardtanh(min_val=0.0, max_val=20.0)\n",
       "      (10): Dropout(p=0.25, inplace=False)\n",
       "      (11): Linear(in_features=1152, out_features=512, bias=True)\n",
       "      (12): Hardtanh(min_val=0.0, max_val=20.0)\n",
       "      (13): Dropout(p=0.25, inplace=False)\n",
       "    )\n",
       "    (prediction): ModuleDict(\n",
       "      (dec_rnn): BNRNNSum(\n",
       "        (layers): ModuleList(\n",
       "          (0): RNNLayer(\n",
       "            (rnn): LSTM(256, 256)\n",
       "          )\n",
       "          (1): Dropout(p=0.25, inplace=False)\n",
       "          (2): RNNLayer(\n",
       "            (rnn): LSTM(256, 256)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (embed): Embedding(28, 256)\n",
       "    )\n",
       "    (joint_net): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=512, bias=True)\n",
       "      (1): Hardtanh(min_val=0.0, max_val=20.0)\n",
       "      (2): Dropout(p=0.25, inplace=False)\n",
       "      (3): Linear(in_features=512, out_features=29, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (loss): RNNTLoss(\n",
       "    (rnnt_loss): RNNTLoss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create all components for config\n",
    "# FYI: if using train-clean-100 & dev-clean this cell takes O(60s) \n",
    "seq_to_seq, epochs, train_loader, eval_loader = build(task_config)\n",
    "seq_to_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of params: 26337181\n"
     ]
    }
   ],
   "source": [
    "print(\"number of params:\", sum(p.numel() for _, p in seq_to_seq.model.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom callback to monitor training and print results\n",
    "class PrintCB(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def on_epoch_end(self, **kwargs):\n",
    "        if self.training:\n",
    "            return\n",
    "        epoch = kwargs[\"epoch\"]\n",
    "        if epoch % 10 == 0:\n",
    "            try:\n",
    "                wer_reports = kwargs[\"reports\"][seq_to_seq.post_process.__class__.__name__]\n",
    "                wer = wer_reports[\"wer\"]\n",
    "                transcripts = wer_reports[\"transcripts\"][0] #take first element\n",
    "                pred, exp = transcripts\n",
    "                pred = \"\".join(pred)\n",
    "                exp = \"\".join(exp)\n",
    "                loss = kwargs[\"reports\"][\"ReportMeanBatchLoss\"]\n",
    "\n",
    "                print(\"{}, pred: {}, exp: {}, loss {:.8f}, wer: {:.4f}\".format(epoch, pred, exp, loss, wer, ))\n",
    "            except KeyError:\n",
    "                print(\"no wer - using new decoder?\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"/home/samgd/logs/rnnt/\" + str(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipEval(Callback):\n",
    "    def __init__(self, up_to=0):\n",
    "        super().__init__()\n",
    "        self.up_to = up_to \n",
    "        \n",
    "    def on_batch_end(self, *args, **kwargs):\n",
    "        if kwargs[\"epoch\"] <= self.up_to and not self.training:\n",
    "            print(\"stop epoch\")\n",
    "            return {\"stop_epoch\": True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    }
   ],
   "source": [
    "from myrtlespeech.run.callbacks.rnn_t_training import RNNTTraining\n",
    "from myrtlespeech.run.run import ReportRNNTDecoder\n",
    "from myrtlespeech.run.run import ReportCTCDecoder\n",
    "from myrtlespeech.run.run import Saver\n",
    "from myrtlespeech.run.run import TensorBoardLogger\n",
    "from myrtlespeech.run.run import WordSegmentor\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    RNNTTraining(),\n",
    "    ReportMeanBatchLoss(),\n",
    "    ReportRNNTDecoder(\n",
    "        seq_to_seq.post_process, \n",
    "        seq_to_seq.alphabet,\n",
    "    ),\n",
    "    TensorBoardLogger(log_dir, seq_to_seq.model, histograms=False),\n",
    "    MixedPrecision(seq_to_seq, opt_level=\"O1\"),\n",
    "    CSVLogger(f\"{log_dir}/log.csv\", \n",
    "        exclude=[\n",
    "            \"epochs\", \n",
    "            #\"reports/CTCGreedyDecoder/transcripts\",\n",
    "        ]\n",
    "    ),\n",
    "    SkipEval(up_to=100)\n",
    "    #StopEpochAfter(epoch_batches=1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop epoch\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 512.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 256.0\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 128.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 64.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32.0\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "stop epoch\n",
      "stop epoch\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
      "stop epoch\n",
      "stop epoch\n",
      "stop epoch\n"
     ]
    }
   ],
   "source": [
    "# Note the SkipEval callback skips computing the WER as it can \n",
    "# take a while whilst the predications are poor\n",
    "fit(\n",
    "    seq_to_seq, \n",
    "    epochs=3000,\n",
    "    train_loader=train_loader, \n",
    "    eval_loader=eval_loader,\n",
    "    callbacks=callbacks,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
